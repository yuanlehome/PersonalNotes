# 1. phi kernel 体系介绍
## 1.1 总体介绍
phi kernel 是 inference 中极具特色的函数式 kernel。

对于一个 op ，op 只是一个操作、或者称为算术的一种抽象描述。这种操作的具体实现，称为 kernel。

我们可以在不同的**硬件平台（后者称为后端）**、针对有不同的 **格式（layout)** 以及不同的 **精度（datatype）** 的数据，实现这种操作。所以一个 Op 的 Kernel 可以有多个。

如何管理大量的 Op 和对应的 Kernel 呢， 很简单，用一个 map 容器即可。且看 phi kernel 中是如何管理的。

phi 中有一个数据结构 `class KernelFactory`，内部有一个 `KernelNameMap kernels_`， (paddle/phi/core/kernel_factory.h)
```cpp
using KernelKeyMap = paddle::flat_hash_map<KernelKey, Kernel, KernelKey::Hash>;
using KernelNameMap = paddle::flat_hash_map<std::string, KernelKeyMap>;
```
即 kernels_ 管理所有的 kernel，KernelNameMap 中根据 op 的名字，可以得到 KernelKeyMap， KernelKeyMap 包含了这个 op 在不同硬件以及针对不同数据类型的实现，
然后根据 KernelKey 得到你最终期望的 kernel。
```cpp
class KernelKey {
 public:
  KernelKey(Backend backend, DataLayout layout, DataType dtype)
      : backend_(backend), layout_(layout), dtype_(dtype) {}
  ...
}
```
KernelKey 正是我们前面所说的**硬件平台（后端）**、**数据格式（layout)**、**数据精度（datatype)** 的抽象数据结构。

最终得到的 phi::Kernel 是一个函数的抽象，phi::Kernel 里面封装着 phi::KernelFn, 这个函数需要参数 phi::KernelContext, phi::KernelContext 可以理解为一个 phi::KernelFn 运行时所需要的上下文信息。
```cpp
using KernelFn = std::function<void(KernelContext* ctx)>;
class Kernel {
 public:
  explicit Kernel(KernelFn fn, void* variadic_fn)
      : fn_(fn), variadic_fn_(variadic_fn) {}
  void operator()(KernelContext* ctx) const { fn_(ctx); }
  ...
}
```
另外一个重要的数据结构 `phi::KernelSignature`，它的目的是为了明确 kernel 的输入输出属性等信息。 kernel 的输入、输出、以及属性其实都是 op 中定义的， 为了不直接从 op 中拿这些信息，进行必要的隔离而设计的 `phi::KernelSignature`。同时这样设计最重要的目的是为了**兼容性**。op 的输入输出以及一些属性有时候是可变的，同时 op 也在升级，不同版本的 op 的输入输出和属性不同。
```cpp
struct KernelSignature {
  const char* name;
  paddle::small_vector<const char*> input_names;
  paddle::small_vector<const char*> attr_names;
  paddle::small_vector<const char*> output_names;
  ...
}
KernelSignature ConcatOpArgumentMapping(const ArgumentMappingContext& ctx) {
  if (ctx.HasInput("AxisTensor")) {
    return KernelSignature("concat", {"X"}, {"AxisTensor"}, {"Out"});
  }
  return KernelSignature("concat", {"X"}, {"axis"}, {"Out"});
}
```
比如 ConcatOp 不同的版本 可以有 AxisTensor 属性（这是一个 tensor 类型），或者一个 axis 属性（这是一个 int 数字）。 phi kernel 必须根据不同的属性类型做不同的处理。我们必须把 KernelSignature 中要求的输入输出以及属性信息准备好，以及 kernel 执行的 device 等信息全部放入 KernelContext 中， 然后作为参数传入 KernelFn 中，正如 `void operator()(KernelContext* ctx) const { fn_(ctx); }`。 这样这个 kernel 就得以正确执行。

phi kernel 核心的数据结构就这么多，这是一个与 op 体系隔离的 kernel 体系设计， phi kernel 体系与前面介绍的 fluid 算子体系之间的桥梁就是 `DenseTensor`。

其他定义
```cpp
// 对一个 op 输出输出以及属性描述的封装，里面的内容就是从 op 的 proto 中获取
class ArgumentMappingContext{

}
// ArgumentMappingFn : 为了方便得到一个 op 对应的 KernelSignature
using ArgumentMappingFn =
    std::function<KernelSignature(const ArgumentMappingContext&)>;
```

# 2. fluid 算子体系介绍
fluid 算子体系是 paddle 中算子体系。

基础的数据结构 `OperatorBase`, 这是一个抽象类，里面只提供虚函数接口。`OperatorWithKernel` 继承自 `OperatorBase`， 正如它的名字所示， OperatorWithKernel 既包含了 op 的描述，也包含了计算时调用 kernel 的逻辑。

`OperatorBase` 有一个公开接口 `Run`， 即运行 Op, Run函数里面调用 `RunImpl;` , RunImpl的实现在 `OperatorWithKernel`中。

对于具体的 op 来说， 如 ConvTransposeOp（"conv_transpose_op.h"）， 继承关系为: `ConvTransposeOp:OperatorWithKernel:OperatorBase`，

`ConvTransposeOp` 中只需要定义 `GetExpectedKernelType`函数，指定 conv_tanspose op 计算时期望运行的 kernel，运行时的调用顺序为：

ConvTransposeOp.Run() --> OperatorWithKernel.RumImp() // RumImp()里会调用 GetExpectedKernelType 函数指定的 kernel。

OperatorWithKernel 中有一个接口 `AllOpKernels()`, 里面的静态变量 g_all_op_kernels 管理着所有 op 的 kernel。
```cpp
using OpKernelFunc = std::function<void(const ExecutionContext&)>;
using OpKernelMap = std::unordered_map<OpKernelType, OpKernelFunc, OpKernelType::Hash>;
static paddle::flat_hash_map<std::string /* op_type */, OpKernelMap>&
  AllOpKernels() {
    static paddle::flat_hash_map<std::string, OpKernelMap> g_all_op_kernels;
    return g_all_op_kernels;
  }
```

正如前面所言， 一个 op 的 kernel 可以有很多种， fluid 算子体系中通过 OpKernelType 来区分不同的 kernel(OpKernelFunc)

fluid 体系中的 OpKernelFunc 定义与 phi kernel 类似， 也是一个函数，需要传入参数 `ExecutionContext`， 表示这个 fluid kernel 的执行环境。`ExecutionContext`里面包含了设备信息， op 的输入输出变量，以及管理所有变量的 scope 等信息。

OpKernelType 与前面 phi 中的 KernelKey 概念完全一样：
```cpp
class OpKernelType {
  ...
  OpKernelType(proto::VarType::Type data_type,
               platform::Place place,
               DataLayout data_layout = DataLayout::kAnyLayout,
               LibraryType library_type = LibraryType::kPlain,
               int customized_type_value = kDefaultCustomizedTypeValue)
  ...
}
```